apiVersion: v1
data:
  build: |-
    # Important doc references
    # - BP general: https://github.com/buildpacks/spec/blob/main/platform.md
    # - Env setup.: https://github.com/buildpacks/spec/blob/main/platform.md#user-provided-variables
    # Parameters
    # - PREIMAGE # url of previous image
    # - APPIMAGE # url of application image
    # - USERID   # id of the `cnb` user
    # - GROUPID  # id of the primary group linked to the `cnb` user
    #
    # ATTENTION: The `curl localhost:4191` command is used to stop the linkerd proxy
    # container gracefully. We use `|| true` in case linkerd is not deployed.  Further, it
    # is placed into a trap to ensure that it will always run, even for a staging failure.
    # Error output generated when linkerd is not present/up is squashed (dev/null).
    # These messages are irrelevant, the situation is not an error, and allowing them through
    # would confuse users (readers of app staging logs).
    set -e
    trap "curl -X POST http://localhost:4191/shutdown 2> /dev/null || true" EXIT
    echo By _ _ __ ___ _____ $(whoami),$(id -u)/$(id -g) $(pwd)
    [ "$HOME" == /home/heroku ] && echo "Setting registry access for Heroku builder" && ln -s /home/cnb/.docker $HOME/.docker
    if test ! -d "/workspace/source/app" ; then
      echo Nothing to build
      sleep 60 # linkerd is a pain - If we exit to quickly, with the sidecar not ready our curl to shut it down does nothing, and then the sidecar comes up and prevents the pod from ending
      exit 1
    fi
    find /workspace
    for path in $(ls /workspace/source/env/* 2>/dev/null) ; do export "$(basename "${path}")"="$(cat "${path}")" ; done
    /cnb/lifecycle/creator \
      -app=/workspace/source/app \
      -cache-dir=/workspace/cache \
      -uid=${USERID} \
      -gid=${GROUPID} \
      -layers=/layers \
      -platform=/workspace/source \
      -report=/layers/report.toml \
      -skip-restore=false \
      "-previous-image=${PREIMAGE}" \
      "${APPIMAGE}"
      echo _ _ __ ___ _____ Done
  builder: '*'
  download: |-
    # Parameters
    # - PROTOCOL # s3 protocol
    # - ENDPOINT # s3 endpoint
    # - BUCKET   # s3 bucket
    # - BLOBID   # blob id / file name for source archive
    #
    # This data is set in the chart only for an external s3.  For
    # internal s3 the chart has no information.  Therefore we cannot
    # use helm templating to insert these.
    echo By _ _ __ ___ _____ $(whoami),$(id -u)/$(id -g) $(pwd)
    echo Image "amazon/aws-cli:2.13.26"
    cat /etc/ssl/certs/ca-bundle.crt               > /tmp/ca-bundle.pem
    test -f /certs/ca.crt   && cat /certs/ca.crt  >> /tmp/ca-bundle.pem
    test -f /certs/tls.crt  && cat /certs/tls.crt >> /tmp/ca-bundle.pem
    aws --ca-bundle /tmp/ca-bundle.pem --endpoint-url "${PROTOCOL}://${ENDPOINT}" s3 cp "s3://${BUCKET}/${BLOBID}" "/workspace/source/${BLOBID}"
    echo _ _ __ ___ _____ Done
  downloadImage: amazon/aws-cli:2.13.26
  env: 'CNB_PLATFORM_API: "0.11"'
  groupID: "1000"
  unpack: |-
    # Parameters
    # - BLOBID  # blob id / file name for source archive
    # - USERID  # id of the `cnb` user
    # - GROUPID # id of the primary group linked to the `cnb` user
    #
    # Attempting to unpack the sources as, in order:
    #    .tar   - epinio cli
    #    .zip   - epinio UI
    # -z .tar.gz
    # -j .tar.bz2
    # -J .tar.xz
    #
    # __Note__: While it would have been nicer, IMNSHO, to use `file` to determine the
    # type of the file and then directly dispatch to the proper unpacker, the `file`
    # command is not available in the `bash` image. The code as written now relies on each
    # unpacker to recognize/reject input properly.
    #
    echo By _ _ __ ___ _____ $(whoami),$(id -u)/$(id -g) $(pwd)
    echo Image "ghcr.io/epinio/epinio-unpacker:v1.11.0"
    if test ! -f "/workspace/source/${BLOBID}" ; then
      echo Nothing to unpack
      exit
    fi
    mkdir /workspace/source/app
    (  cd /workspace/source/app
       ( echo Tar? ; tar -xvf  "../${BLOBID}" ) || \
       ( echo Zip? ; unzip     "../${BLOBID}" ) || \
       ( echo Tgz? ; tar -xvzf "../${BLOBID}" ) || \
       ( echo Tbz? ; tar -xvjf "../${BLOBID}" ) || \
       ( echo Txz? ; tar -xvJf "../${BLOBID}" ) || \
       ( echo "Unable to unpack. No supported archive file format found" ; exit 1 )
       echo OK
       if test $(find . -maxdepth 1 -mindepth 1 -printf %y)  = "d" ; then
         # archive contains single element which is a directory. assume that the actual
         # app sources are inside it, and lift them out to match paketo's expectations.
         child="$(ls)"
         echo Lifting \"${child}\" contents ...
         mv -v "${child}"/* "${child}"/.??* .
         rmdir -v "${child}"
       fi
    )
    rm "/workspace/source/${BLOBID}"
    mkdir -p /workspace/source/env
    cp -vL /workspace/source/appenv/* /workspace/source/env 2>/dev/null
    for path in $(ls /workspace/source/env/* 2>/dev/null) ; do echo "$(basename "${path}")"="$(cat "${path}")" ; done
    chown -R ${USERID}:${GROUPID} /workspace 2> /dev/null
    find /workspace
    echo _ _ __ ___ _____ Done
  unpackImage: ghcr.io/epinio/epinio-unpacker:v1.11.0
  userID: "1001"
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: epinio
    meta.helm.sh/release-namespace: epinio
  labels:
    app.kubernetes.io/component: epinio-staging
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: epinio
    app.kubernetes.io/version: v1.11.0
  name: epinio-stage-scripts
  namespace: epinio
